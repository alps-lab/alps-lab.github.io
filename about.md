---
title: About
layout: page
permalink: /about/index.html
---

<!-- ![img]({{ site.url }}/assets/images/newprofile.jpg) -->



<img src="/assets/images/newprofile.jpg" alt="profile" width="15%"/>
<!-- <img src={{ site.url }}/assets/images/newprofile.jpg width="200" /> -->

<hr>

### About Me

I am Empire Innovation Associate Professor in the Department of Computer Science at Stony Brook University. I conduct research at the interface of machine learning, privacy, and security. I direct the [Algorithmic Learning, Privacy, and Security]({{ site.baseurl }}/alps) (ALPS) Lab. The overarching goal of my research is to maximize the practical impact of artificial intelligence (AI) by bridging technological advances and transformative applications. To this end, my recent work focuses on improving AI technologies along three major thrusts:
 * Security Assurance -- *resilient against malicious manipulations*
 * Privacy Preservation -- *respectful for individual privacy*
 * Decision-Making Transparency -- *interpretable to human perception*

I obtained my doctoral degree from Georgia Tech and completed my undergrad study at Zhejiang University (China).


<hr>

### Recent News

<ul>
<li><label class="paper_label_style">Paper</label> <a href="">CTRL</a> (ICCV'23) presents an embarrassingly simple yet highly effective backdoor attack against self-supervised learning. </li>
<li><label class="paper_label_style">Paper</label> <a href="https://arxiv.org/pdf/2305.02383.pdf">ROAR</a> (USENIX'23) systematically studies the security vulnerabilities of knowledge graph-based reasoning systems. </li>
<li><label class="info_label_style">Award</label>  <a href="https://arxiv.org/pdf/2302.10827">AutoML in the Wild</a> (CHI'23 Honorable Mention) interviews real-world users to understand the limitations they face in using AutoML, how they work around such obstacles, and their expectations for future advances of AutoML. </li>
<li><label class="paper_label_style">Paper</label> <a href="https://www.usenix.org/system/files/sec23fall-prepub-85-fu-chong.pdf">FreeEagle</a> (USENIX'23) detects complex backdoors in neural networks without access to any data. </li>
<li><label class="paper_label_style">Paper</label> <a href="https://openreview.net/pdf?id=bsZULlDGXe">Dark Side of AutoML</a> (ICLR'23) explores the possibility of leveraging AutoML as a new attack vector to launch previously improbable attacks.  </li>
<!-- <li><label class="paper_label_style">Paper</label> <a href="">AIRS</a> (USENIX'23) faithfully explains the most critical steps in deep reinforcement learning, supporting a range of security applications. </li> -->
<li><label class="fund_label_style">Grant</label> NSF award to support our research on <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2212323">the Security Risks of AutoML</a>. Thank you, NSF! </li>
<li><label class="info_label_style">Award</label> <a href="https://dl.acm.org/doi/10.1145/3533767.3534410">Android App Analysis</a> received the ACM SIGSOFT Distinguished Paper award! </li>
<!-- <li><label class="paper_label_style">Paper</label> <a href="https://arxiv.org/pdf/2111.10991">Spectral Backdoor Attack</a> accepted by ECCV '22. </li>
<li><label class="paper_label_style">Paper</label> <a href="">Adversarial Attack on Text</a> accepted by KDD '22. </li>
<li><label class="talk_label_style">Internship</label> Ren >> Meta, Zhaohan >> Uber, Changjiang >> JD. Enjoy your summer!</li>
<li><label class="success_label_style">Promotion</label> Ting is tenured and promoted. Thank you, Penn State!</li>
<li><label class="paper_label_style">Paper</label> <a href="">Stability of Deep Learning Interpretability</a> accepted by CCS '22. </li>
<li><label class="paper_label_style">Paper</label> <a href="https://arxiv.org/pdf/2204.04063">Transferable Adversarial Attack</a> accepted by S&P '22. </li>
<li><label class="paper_label_style">Paper</label> (i) <a href="https://arxiv.org/pdf/2110.06018.pdf">AutoML</a>, (ii) <a href="https://arxiv.org/pdf/2202.10673.pdf">Deepfake</a>, (iii) <a href="https://www.usenix.org/system/files/sec22summer_yu-le.pdf">Vehicle Diagnostic Protocol</a>, (iv) <a href="https://www.usenix.org/system/files/sec22summer_fu.pdf">Label Inference Attack</a>, (v) <a href="https://www.usenix.org/system/files/sec22summer_fang.pdf">Cyber Attack Causality Analysis</a>, and (vi) <a href="https://www.usenix.org/system/files/sec22summer_li-jianfeng.pdf">Android App Fingerprinting</a> accepted by USENIX '22. </li>
<li><label class="paper_label_style">Paper</label> (i) <a href="https://arxiv.org/pdf/2012.09302.pdf">Neural Backdoor Evaluation</a> and (ii) <a href="">Fair and Robust Classification</a> accepted by EuroS&P '22. </li>
<li><label class="paper_label_style">Paper</label> <a href="">Hard-Label Adversarial Attack on Text</a> accepted by AAAI '22. </li> -->
<!-- <li><label class="fund_label_style">Grant</label> NSF Award for <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=2119331">Extreme-Scale Edge Learning for Healthcare</a>. Thank you, NSF! </li>
<li><label class="success_label_style">Award</label> Ting recognized with <a href="https://news.psu.edu/story/653278/2021/04/01/academics/information-sciences-and-technology-faculty-staff-recognized?utm_source=newswire&utm_medium=email&utm_term=653377_HTML&utm_content=04-01-2021-10-36&utm_campaign=IST%20newswire">Research Excellence Award</a>. Thank you, Penn State!</li>
<li><label class="info_label_style">Graduation</label> Xinyang >> Baidu Research. Congrats! </li>
<li><label class="info_label_style">Graduation</label> Zheng >> CS@Northwestern. Congrats! </li>
<li><label class="paper_label_style">Paper</label> 2 papers on (i) <a href="">RNN Certification</a> and (ii) <a href="">Transferable Backdoor Attack</a> accepted by <em>CCS '21</em>. </li>
<li><label class="paper_label_style">Paper</label> 1 paper on <a href="https://arxiv.org/pdf/2008.00312.pdf">Language Model Backdoor</a> accepted by <em>Euro S&P '21</em>. </li>
<li><label class="paper_label_style">Paper</label> 3 papers on (i) <a href="https://arxiv.org/pdf/2006.11890.pdf">Graph Backdoor</a>, (ii) <a href="https://arxiv.org/pdf/2010.01785.pdf">Fuzzing Evaluation</a>, and (iii) <a href="">Attacks on Lane Detection</a> accepted by <em>USENIX '21</em>. </li>
<li><label class="paper_label_style">Paper</label> 1 paper on <a href="https://arxiv.org/pdf/2101.09301.pdf">Interactive Interpretability</a> accepted by <em>AAAI '21</em>. </li> -->

<!-- <li><label class="paper_label_style">Paper</label> Papers on UI Obfuscation and Diehard Android Apps accepted by ASE '20. </li> -->
 <!-- <li><label class="fund_label_style">Grant</label> DARPA grant for <a href="https://ist.psu.edu/research/projects/HORUS">Threat Responses under Stress</a>. </li>
<li><label class="paper_label_style">Paper</label> Paper on <a href="https://arxiv.org/pdf/2006.09539.pdf">Adversary's Intent Inference </a> accepted by <em>KDD '20</em>. </li>
<li><label class="paper_label_style">Paper</label> Papers on (i) <a href="https://arxiv.org/pdf/1911.01559.pdf">Adversarial-Input-Trojan-Model Dynamics</a> and (ii) <a href="{{ site.url }}/paper/Shi-ccs-2020.pdf">Text Captcha Evaluation </a> accepted by <em>CCS '20</em>. </li>
<li><label class="paper_label_style">Paper</label> Papers on (i) <a href="https://arxiv.org/abs/1812.00891">Security of Interpretable Learning</a> and (ii) <a href="{{ site.url }}/paper/Li-usenix-2020.pdf">Robust Text Classification</a> accepted by <em>USENIX '20</em>. </li>
<li><label class="success_label_style">Award</label> Ting recognized with <a href="https://news.psu.edu/story/619467/2020/05/11/academics/ist-announces-2020-deans-circle-teaching-excellence-recipients">Teaching Excellence Award</a>. Thank you, Penn State!</li>
<li><label class="fund_label_style">Grant</label> NSF Award for <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1910546">Usable Interpretability</a>. Thank you, NSF! </li> -->

<!--
<li><label class="paper_label_style">Paper</label> Paper on <a href="{{ site.url }}/paper/chen-ccs19.pdf">Inconsistency of Cryptocurrency Tokens</a> accepted by CCS '19. </li>
<li><label class="info_label_style">Job</label> Ting  Penn State! </li>
<li><label class="paper_label_style">Paper</label> Paper on <a href="https://www.ncbi.nlm.nih.gov/pubmed/31331902">Rare Class Mining</a> accepted by IEEE Cybernetics. </li>
<li><label class="success_label_style">Award</label> Ting recognized with <a href="https://engineering.lehigh.edu/news/article/rossin-awards-honor-excellence-across-lehighs-engineering-college">Rossin Assistant Professorship</a>. Thank you, Lehigh!</li>
<li><label class="fund_label_style">Grant</label> NSF CAREER Award for <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1846151">Trustworthy Machine Learning from Untrusted Models</a>. Thank you, NSF! </li>
<li><label class="info_label_style">Job</label> Ningfei -> ICS@UC Irvine. Congrats! </li>
<li><label class="info_label_style">Job</label> Yifan -> INI@CMU. Congrats! </li>
<li>01/18 <label class="paper_label_style">paper</label> Our paper on <font color="blue"><em>differentially private  online learning</em></font> accepted by IEEE TKDE </li>
<li>11/17 <label class="paper_label_style">paper</label> Our paper on <font color="blue"><em>graph anonymity</em></font> accepted by INFOCOM '18 </li>
<li>10/17 <label class="paper_label_style">paper</label> Our paper on <font color="blue"><em>adversarial model</em></font> awarded the <font color="red">best paper award</font> at IEEE CNS'17! </li>
<li>08/17 <label class="fund_label_style">fund</label> Grateful for a grant by NSF to support our research on adversarial deep learning (<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1718787">details</a>) </li>
<li>07/17 <label class="paper_label_style">paper</label> Our paper on <font color="blue"><em>adversarial model</em></font> accepted by IEEE CNS'17  </li>
<li>06/17 <label class="paper_label_style">paper</label> Our paper on <font color="blue"><em>graph privacy</em></font> accepted by IEEE TDSC </li>
<li>04/17 <label class="paper_label_style">paper</label> Our paper on <font color="blue"><em>private deep learning</em></font> accepted by IEEE ICDCS'17 </li>
<li>05/16 <label class="paper_label_style">paper</label> Our <font color="blue"><em>computational creativity</em></font> paper is accepted by <a href="http://cikm2016.cs.iupui.edu">ACM CIKM'16</a>. </li>
<li>05/16 <label class="talk_label_style">talk</label> Ting is invited to give a presentation at the <a href="http://cra.org/ccc/events/computing-innovation-societal-needs-the-impact-of-computing-research/">CCC Symposium on Computing Research</a> </li>
<li>03/16 <label class="paper_label_style">paper</label> Our <font color="blue"><em>botnet population estimation</em></font> paper is accepted by <a href="http://www-higashi.ist.osaka-u.ac.jp/icdcs2016/">IEEE ICDCS'16</a>.</li>
<li>03/16 <label class="fund_label_style">fund</label> We are awarded a grant by NSF to support our research on deep learning-powered mobile services. Find details <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1566526">here</a>. </li>
<li>02/16 <label class="paper_label_style">paper</label> Our <font color="blue"><em>beaconing detection</em></font> paper is accepted by <a href="https://dsn-2016.sciencesconf.org">IEEE DSN'16</a>. </li>
<li>11/15 <label class="paper_label_style">paper</label> Our <font color="blue"><em>malicious web infrastructure detection</em></font> paper accepted by <a href="http://infocom2016.ieee-infocom.org">IEEE INFOCOM'16</a>. </li>
<li>11/15 <label class="paper_label_style">paper</label> One <font color="blue"><em>exploit kit detection</em></font> paper accepted by <a href="https://sites.google.com/site/codaspy20162/">ACM CODASPY'16</a>.</li>
<li>08/15 <label class="job_label_style">job</label> Ting has started as Assistant Professor at Lehigh! </li> -->

</ul>

<hr>

### Contact Information

<ul style="list-style-type:none">
	<li>ðŸ“© twang@cs.stonybrook.edu (or inbox.ting@gmail.com)</li>
	<li>ðŸ“ž TBA </li>
	<li>ðŸ“ª New Computer Science Building Room 154, Stony Brook University, NY 11794 </li>
</ul>

<hr>


### Join Us!

We are ALWAYS looking for motivated and bright (under)grad students and postdocs. If you know how to build/hack AI systems, we should talk! Please email me your resume and set up a time to discuss your potential fit to our team.
